\section{Evaluation}
\label{chapter:evaluation}

This chapter discusses the evaluation criteria with dataset simulation as well as 
the issues and solutions on social and ethical aspects appears with this system design.
Surely, our system still has limitations, 
we then discusse the most important two limitations within our system: 
evaluation outdated and game playability.

\subsection{Success Criterias}

\subsubsection{Model Evaluation by Simulation}

In the previous chapter of design and model, we descrived the system data flow, which is
done by three main step: task generation, malicious player detection and disaster level evaluation as well.
The second step malicious player detection is essentially a classification problem that 
our system detect the new player is reliable or not based on \hyperref[def:tv]{Trust Value}.

To evaluate our model, a typical classification model performance evaluation metric is to 
using the Receiver Operating Characteristic (ROC) curve \cite{hanley1982meaning}, which 
plots True Positive (on the y-axis) against False Positive and the ideal area under the curve
should be 1.
Nevertheless, before we test the system with real user, one can generate a reaonsable random dataset 
to test the performance of our classification model (\hyperref[idx:prm]{PRM}).

Our player have two different type of inputs: \textbf{the \hyperref[def:roi]{ROI}, 
and its \hyperref[def:tagv]{Tag Vector}}. For a reaonsable player data entity, 
one has to define the ROI selection and its corresponding Tag Vector.
To generate resonable ROI to simulate real user behavior, we disscuss the click behavior
of a desktop target click behavior first.

The target click behavior has been researched for years and address by FFitts Law \cite{bi2013ffitts}.
It modeled and proved the distribution of click behavior for a certain click goal point is a Gaussian distribution \cite{goodman1963statistical}.
Thus, with frequency statistic view, the actual ROI(s) for a certain exists, 
and whatever the user start from the top right corner or bottom left corner or etc., 
according to the FFitts Law, the starting click point should follows normal distribution around the actual point,
as shown in figure \ref{fig:evaluation}. Similarly, the landing point of the selection of ROI(s)
should also follows a normal distribution. 

\begin{figure}[htp]
\centering
\includegraphics[width=0.5\columnwidth]{figures/evaluation}
\caption{Example of ROI Simulation}
\label{fig:evaluation}
\end{figure}

Therefore, to generate ROI(s), let $(x, y)$ is the player ROI starting point, $(H_{ROI}$, $W_{ROI})$ is the height
and width pair of this ROI, then we generate noise for the ROI starting points and landing points: 
$(x+\epsilon, y+\epsilon), (H_{ROI}+\epsilon, W_{ROI}+\epsilon)$ and $\epsilon \sim N(0, \delta)$.
For the paremeter $\delta$, one can use Maximum Likelihood estimator \cite{johansen1990maximum} 
to perform the inference from all manually ROI selection samples from initial trusted group.

The generation of Tag Vector for a certain image is much simple than ROI's, 
a randomly pick from initial trusted group is sufficient for the simulation case 
because these tags are trusted results and a partial randomly selection already introduced the noise in this case.

Eventually, one can perform this random dataset on the system to evaluate area under the ROC curse to
evaluate the overall performance of this system (the model shows good performance if the value approximate to 1), 
which gives the theoretical evaluation results.

\subsubsection{Issues on Social and Ethical Aspects}
\label{chapter:ethical}

\textbf{Intellectual Property Rights:} 
Our disaster monitoring \hyperref[idx:hc]{HC} system is an non-commercial project which invites volunteers to contribute to it. 
It is used to help the UNICEF and other non-profit organizations deliver supplies in disaster areas safer. 
So the IPR on the annotations should not belong to the volunteer users. In an appropriate manner, user will be informed that 
his or her contribution to the system is volunteering and the produced data will be used only for 
monitoring disasters in Syria.

\textbf{Leakage of data:} 
The users may get important geographic information which should not be leaked from the satellite images. So we cut big image into small segmentations in our 











system to prevent data leakage to ordinary users. 
The \textbf{data security} is also very important and needs to be considered with high priority on the side of stackholders. For example, 
the backend database should not be entirely accessible to every employee of UNICEF or any other organization running the system.
Each of them can only visit the part of data that they need at present. This principle is made to guarantee 
that data will not be wrongly used and will be included in our future work.

\textbf{Information Loss}
We cut big region images into small fragements areas to prevent leakage of data. 
But this method will cause some information loss problem if some important ROIs are 
located at the intersection of two dividing lines.
A possible solution for this limitation is to consider new regions that contains the loss
informations, as shown in figure \ref{fig:information_loss}. Note that this solution that
only increases the number of region pictures, it does not influence any model and system design.


\begin{figure}[H]
\centering
\includegraphics[width=0.7\columnwidth]{figures/information_loss3}
\caption{\textbf{Information Loss}: TODO: fix here. Information loss may occurs on the intersection lines, as shown on the left; a possible solution
is to provide additional regions (blue rectangles) for these special area as shown on the right.}
\label{fig:information_loss}
\end{figure}

\subsection{Limitations of the System}

\subsubsection{Evaluation Outdated}

TODO: rewrite this section, gives few time series prediction method.

A limitation occurs in our social network based model is each disaster level evaluation get invalid 
if the region image is outdated. 
We assume the satellite monitors an area and take pictures between intervals. However, our evaluation
the model only calculate the disaster level at a unique moment, which means the disaster level need 
transvaluation when a new image comes out.
If our player is not enough so that the region images always have to wait for new evaluation, then the
disaster level will never be calculated.

A possible solution is to consider the region disaster level history as a time series. Then we can apply
some prediction method for it. For instance, we have time series: $(t_1, t_2, t_3, ..., t_n)$
and its corresponding disaster level: $(DL_1, DL_2, DL_3, ..., DL_n)$.
Then we can use these time series to predict the disaster level at time $t_{n+1}$.

At the same time, we also have the historical data of trust value of a player. We can also
use time series prediction to predict the player's trust value. But in all of these, the time series
of disaster level is not stationary but the time series of trust value is stationary.

TODO: Fix here by given few prediction method suggestions.

\subsubsection{Gameplay and Playability}

TODO: add image here, rewrite this paragraph.

The GWAP collects satellite photos of disaster areas. But even if in the disaster areas, 
not every part of the areas has a disaster. Most parts of the earth are lake, forest, 
desert and so on, which means the users may meet the situation that there is no available 
ROI in several continuous rounds. Obviously, it will decrease the playability and enjoyment of the game.
Our system is just a very simple tagging game at present, users can not get enough enjoyment they want in it. 
And it is too reliant on the unpaid volunteers to donate their time to contribute information. 
We should make the system more interesting and appealing in the future work.
